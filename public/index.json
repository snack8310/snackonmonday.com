[{"categories":null,"content":"安装Rust","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:1","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#安装rust class=headerLink"},{"categories":null,"content":"创建一个新项目cargo new ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:2","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#创建一个新项目 class=headerLink"},{"categories":null,"content":"hello worldcargo run/build ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:3","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#hello-world class=headerLink"},{"categories":null,"content":"安装frameworkactix/rocket ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:4","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#安装framework class=headerLink"},{"categories":null,"content":"hello world in framework","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:5","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#hello-world-in-framework class=headerLink"},{"categories":null,"content":"安装数据库disiel/sqlx ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:6","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#安装数据库 class=headerLink"},{"categories":null,"content":"访问一个数据库查询","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:7","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#访问一个数据库查询 class=headerLink"},{"categories":null,"content":"一个short code项目","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:8","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#一个short-code项目 class=headerLink"},{"categories":null,"content":"api create code get original url first page ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:9","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#api class=headerLink"},{"categories":null,"content":"以下需要思考是否需要介绍Docker部署 ","date":"2022-10-01","objectID":"/make_a_rust_web_server/:0:10","series":null,"tags":null,"title":"用rust开发一个短链接Server","uri":"/make_a_rust_web_server/#以下需要思考是否需要介绍 class=headerLink"},{"categories":null,"content":"需求场景","date":"2022-08-15","objectID":"/data_warehouse_in_apps/:1:0","series":null,"tags":null,"title":"在应用层实现数据仓库","uri":"/data_warehouse_in_apps/#需求场景 class=headerLink"},{"categories":null,"content":"实现方式","date":"2022-08-15","objectID":"/data_warehouse_in_apps/:2:0","series":null,"tags":null,"title":"在应用层实现数据仓库","uri":"/data_warehouse_in_apps/#实现方式 class=headerLink"},{"categories":null,"content":"实现细节","date":"2022-08-15","objectID":"/data_warehouse_in_apps/:3:0","series":null,"tags":null,"title":"在应用层实现数据仓库","uri":"/data_warehouse_in_apps/#实现细节 class=headerLink"},{"categories":null,"content":"测试的本质","date":"2022-07-20","objectID":"/api_test_automation/:1:0","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#测试的本质 class=headerLink"},{"categories":null,"content":"测试价值现在软件开发领域中，基于狭隘的功能产品测试定义，测试一直是一个成本投入和系统质量的平衡产物。 ","date":"2022-07-20","objectID":"/api_test_automation/:1:1","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#测试价值 class=headerLink"},{"categories":null,"content":"常见的测试问题基于成本投入的问题，常见的问题也可以预想到： 测试资源不足。 遗漏的测试点造成了故障。 改动造成其他业务收到影响。 高并发的场合无法充分测试。 另一个管理视角下： 不好衡量测试资源的缺口 测试并不容易体现个人价值，善战者无赫赫之功。 测试作业强依赖人的主观能力。 ","date":"2022-07-20","objectID":"/api_test_automation/:1:2","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#常见的测试问题 class=headerLink"},{"categories":null,"content":"测试问题的本质细分上述问题，会看到主要的问题，出现在“测试人员”这个资源点。 这个资源点数量充分，则问题就会比较少；资源点能力好，则问题也会比较少。 回到测试价值的说明，测试是个成本投入和系统质量平衡的产物，注定不会有富裕的资源，有什么更好的办法解决。 ","date":"2022-07-20","objectID":"/api_test_automation/:1:3","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#测试问题的本质 class=headerLink"},{"categories":null,"content":"选择自动化测试","date":"2022-07-20","objectID":"/api_test_automation/:2:0","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#选择自动化测试 class=headerLink"},{"categories":null,"content":"自动化测试意义为了尝试解决“测试人员”资源，大家逐渐尝试使用一些工具去执行，行业里也产生了大量的自动化的测试概念和工具。 比较典型的分类就是UI测试，接口测试，单元测试。 ","date":"2022-07-20","objectID":"/api_test_automation/:2:1","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#自动化测试意义 class=headerLink"},{"categories":null,"content":"自动化测试的三个层级 UI自动化：通过Web，移动端的操作录制等方式，验证系统用户操作的脚本 接口自动化：面向服务端的接口，进行数据验证 单元测试自动化：研发开发过程中，进行的开发单元的测试 越往上，测试难度越大，测试构建成本越大。 是不是越往下越好。也不是。 单元测试接口，更多的是开发资源，这部分需要跟业务产出价值PK，开发效率的降低和质量的提升比，并没有明显的优势。 ","date":"2022-07-20","objectID":"/api_test_automation/:2:2","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#自动化测试的三个层级 class=headerLink"},{"categories":null,"content":"怎么选择使用哪部分的自动化测试还是基于成本和收益，平衡的看各自业务的情况进行选择。 如果是一个偏金融交易支付，数字高敏感的，建议采用单元测试+接口自动化 如果是一个偏用户体验的c端产品，优先UI自动化，防止因为一些zz的流程事故，造成的满意度下降。 如果是一个新项目，需要快速落地，拿到市场反馈，建议-不要使用自动化工具。 但是对于一般的项目来说，使用接口自动化测试，是可以长期降低测试资源成本的方案。 ","date":"2022-07-20","objectID":"/api_test_automation/:2:3","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#怎么选择使用哪部分的自动化测试 class=headerLink"},{"categories":null,"content":"怎么做接口自动化测试当然上述一个概念性的评估，我们来看一下，具体怎么构建一个自动化的测试。这个行业里比较成熟，引入一套接口测试自动化框架，还是很快的。 系统构建这类框架基本特点是，脚本化语言+数据统计+报告工具。 自动化测试框架有很多种，例如UI的 Selenium， Katalon，接口的 Allure，很多大厂也有自研的体系。 Allure是我们选择的方案。 整个核心模块是Python，Jenkins，Allue ","date":"2022-07-20","objectID":"/api_test_automation/:2:4","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#怎么做接口自动化测试 class=headerLink"},{"categories":null,"content":"怎么做接口自动化测试当然上述一个概念性的评估，我们来看一下，具体怎么构建一个自动化的测试。这个行业里比较成熟，引入一套接口测试自动化框架，还是很快的。 系统构建这类框架基本特点是，脚本化语言+数据统计+报告工具。 自动化测试框架有很多种，例如UI的 Selenium， Katalon，接口的 Allure，很多大厂也有自研的体系。 Allure是我们选择的方案。 整个核心模块是Python，Jenkins，Allue ","date":"2022-07-20","objectID":"/api_test_automation/:2:4","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#系统构建 class=headerLink"},{"categories":null,"content":"基础环境配置 物理机，虚拟机还是容器化均可。安装Python，Jenkis，Allure的对应版本。 我们是个容器化的构建环境，主要的时间花费在于建立一个基本的版本镜像。以及安装Jenkins，Allue后的插件配置上。 打通代码编译脚本和Jenkins的访问环境，编译实时拉取最新的测试脚本。 建立自动化项目和测试环境及数据库的访问授权，如果是一个空间下，可选择忽略。 在编译环境下增加一个“钩子”，用来将来触发自动化脚本实施，进行自动化的回归。这一个可选，非必须。 以上就是完整的自动化测试框架， 额外提示，由于整个测试链路是在测试环境中构建，并不需要高可用的配置，但要尽量把存储配置做到备份，毕竟工具插件，及测试用例执行器是不停的修改，一旦故障丢失，重新配置还是很疼的。 ","date":"2022-07-20","objectID":"/api_test_automation/:2:5","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#基础环境配置 class=headerLink"},{"categories":null,"content":"测试人员本地 Python Allure ","date":"2022-07-20","objectID":"/api_test_automation/:2:6","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#测试人员本地 class=headerLink"},{"categories":null,"content":"测试脚本的demo @allure.feature('查询数据源数据') class TestDatasource: # 前置条件 @pytest.fixture(scope='class', autouse=True) def setup_class(cls, initialize): global host host = initialize.get('avengers-datasource') data_param,data_ids=read_yaml(__file__,'queryDatasource.yml') @allure.story('查询数据源数据') @pytest.mark.parametrize(\"args\",data_param,ids=data_ids) def test_datasource(self,args): with allure.step('调用datasource-query接口'): response = DatasourceController( host).query_datasourceReport('6', (args['body'])) LogHandler.info(response) assert response['code'] == 0,'查询数据失败' assert args['expected']==response['data'],'数据比对不上' ","date":"2022-07-20","objectID":"/api_test_automation/:2:7","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#测试脚本的demo class=headerLink"},{"categories":null,"content":"自动化测试的心得","date":"2022-07-20","objectID":"/api_test_automation/:3:0","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#自动化测试的心得 class=headerLink"},{"categories":null,"content":"与传统测试的区别流程节点的转变\" 流程节点的转变 比较明显的改变：测试与编码流程没有前后节点关系，意味着： 没有冒烟测试环节 测试与开发资源投入时间无依赖 图以外的差异： 测试的主要时间花费在数据构建上。 测试资源入场可前置，与开发并行。 测试失败场景下，无需测试二次投入。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:1","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#与传统测试的区别 class=headerLink"},{"categories":null,"content":"自动化测试的优点 从实战来说，要达到一个稳定的系统质量，成本是一个比较明显的优点。 做一个粗略的评估，假设一个项目的人力测试成本为1的化，投入测试脚本的时间，保守的说可能是1.5。那么如果项目的第二次迭代，这是非常普遍的事情，测试脚本的修改平均用不上0.5。也就是第二次迭代起，自动化的收益就已经可以持平。 系统回归场景有显著的时间优势。 可以更快速的实施压力测试和性能测试。 可以有效避免重复的故障二次发生。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:2","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#自动化测试的优点 class=headerLink"},{"categories":null,"content":"自动化测试的缺点 对于新项目的测试用例脚本编写时间显著拉长，意味着探索类项目，需要快速反馈的项目，不适用同时执行自动化。 需要配合测试增加一些数据制作的接口，这是额外增加的成本。 自动化并不能发现新问题。引入自动化后，降低的故障率是重复的错误部分，并不能防患于未然。 对人员能力要求高。这部分是引入自动化测试后遇到的最明显的问题。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:3","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#自动化测试的缺点 class=headerLink"},{"categories":null,"content":"关于测试人员的变化自动化测试，是把测试工作编程一些代码逻辑，虽然这个代码逻辑的脚本不需要像项目工程的高要求，但本身这个动作已经属于开发的一部分，对很多测试人员来说是不适应的。 可以尝试做以下的事情： 测试作为验收人员，写测试用例，研发完成测试脚本。 引入部分开发人员，构建基本的脚本，测试同学在基础上去改造，二次加工。修改要比新建容易很多。 测试开发一体。把脚本做成开发作业的一部分。测试直接验收UI。部分测试角色转变为测试开发，以提供更好的数据构建环境，降低测试脚本开发成本。 越往下，对测试的角色要求越低，对测试的能力要求越高。可以根据不同的实际情况，做选择。 必要的情况下，引入新的外部资源。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:4","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#关于测试人员的变化 class=headerLink"},{"categories":null,"content":"接口自动化的改善关注指标 需求量和测试用例比例 — 意味着新编写的用例越来越少，测试作业量的减少。 系统故障和测试用例数量 — 系统稳定性的提升，重复事故的减少。 回归用例测试执行时长和频率 — 回归时间越短，频率越高，系统越稳定。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:5","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#接口自动化的改善关注指标 class=headerLink"},{"categories":null,"content":"如何评估收益理想情况下，自动化测试的收益，会在测试用例密度到达某个临界点后，显著提高。从而达到更好的测试开发人员对比。产品上线的密度增加，系统故障率的降低。 回归到测试的本质，长期来看，关注下述的指标。 测试开发比。 测试事故率。 ","date":"2022-07-20","objectID":"/api_test_automation/:3:6","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#如何评估收益 class=headerLink"},{"categories":null,"content":"总结自动化测试的价值，即使没做过的人也能想象得到。但什么时机选择自动化，选择什么类型的，以及是否使用单元测试，使用UI自动化等，都要回归测试的本质。看投入的成本，带来的是否是正向的收益。究其根本，测试是个用来规避风险，而不是创造价值的，很容易被大家轻视。 构建一套接口自动化测试框架并不复杂 引入之后会有一些人员和流程的适配成本 从实战来说，这是个长期来看有效降低成本的项目，也是比较容易快速试错的项目，值得花时间去尝试。 ","date":"2022-07-20","objectID":"/api_test_automation/:4:0","series":null,"tags":null,"title":"选择自动化测试-一个降成本的选择","uri":"/api_test_automation/#总结 class=headerLink"},{"categories":null,"content":"2B的Saas化，从自产到自销的转变就像演而优则导一样，很多“成功”的公司内部的平台化工具，或主动或被动的，走向了2B的市场，走向了Saas的服务模式。 这些系统或工具，天然具备着行业的成功经验，自信满满的推出。但其中大部分项目都是灰头土脸的失败。 典型的问题：明明是一个高科技公司，做的越来越像一个软件开发公司，甚至绝大多数都不如一个软件公司。 这里面，有很多原因，是因为自产到自销的完全不同的差异性造成的。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:1","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#2b的saas化从自产到自销的转变 class=headerLink"},{"categories":null,"content":"自销遇到的问题 定制化需求 价值认可 定制化需求不可避免的，2B系统的最大的挑战就是定制化。”明明在我们内部适用的功能，运转了3年5年的流程，客户用不了“，”我们认为不重要，但客户要求有“。 定制化是对系统通用性的一种破坏。 价值认可过去是一起解决问题，业务产研测都很关注业务结果。 2B的场景，会认为更多的是一个工具。评价工具的价值是使用的体验，而非使用结果。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:2","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#自销遇到的问题 class=headerLink"},{"categories":null,"content":"自销遇到的问题 定制化需求 价值认可 定制化需求不可避免的，2B系统的最大的挑战就是定制化。”明明在我们内部适用的功能，运转了3年5年的流程，客户用不了“，”我们认为不重要，但客户要求有“。 定制化是对系统通用性的一种破坏。 价值认可过去是一起解决问题，业务产研测都很关注业务结果。 2B的场景，会认为更多的是一个工具。评价工具的价值是使用的体验，而非使用结果。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:2","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#定制化需求 class=headerLink"},{"categories":null,"content":"自销遇到的问题 定制化需求 价值认可 定制化需求不可避免的，2B系统的最大的挑战就是定制化。”明明在我们内部适用的功能，运转了3年5年的流程，客户用不了“，”我们认为不重要，但客户要求有“。 定制化是对系统通用性的一种破坏。 价值认可过去是一起解决问题，业务产研测都很关注业务结果。 2B的场景，会认为更多的是一个工具。评价工具的价值是使用的体验，而非使用结果。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:2","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#价值认可 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#定制化需求解决方案 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#优缺点 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#每个客户独立一个副本 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#一套系统业务中兼容 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#业务模块化 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#模块化可配置的业务单元 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#模块化的方案与业务中兼容的差异 class=headerLink"},{"categories":null,"content":"定制化需求解决方案 独立副本，维护多套系统 一套系统，业务中尽可能的兼容 业务模块化 优缺点每个客户独立一个副本 容易满足客户要求 研发维护成本高 未来功能升级需要在多套环境重复开发 一套系统，业务中兼容 维护成本低 易于升级 业务抽象要求高，容易产生设计不足，或过度设计 业务代码异常复杂，代码”屎山“的罪魁祸首 业务模块化 维护成本低 业务抽象的要求低 容易满足客户需求 基于业务模块的COPY，有一定的系统功能冗余 业务边界调整造成的模块开发。 模块化：可配置的业务单元理想情况下，系统可以构建一个业务单元池，通过一个有着依赖关系的业务单元池，快速选配出一个可用的产品，好比一个乐高积木拼搭的世界。 把客户的定制化产品，做成一个快速插拔的单元模块，从而替代系统已有模型。 无论是画面端还是服务端，使用更多的业务单元化的实例，替代一些业务代码逻辑判断。例如，一个订餐系统中，交付给某个客户的结果是使用通用的支付模块，用户身份认证模块，下单购物车模块，加上一些定制的用户选择功能模块。把川菜馆还是个拉面馆的差异封装成两个定制化的下单菜单。完全定制。 模块化的方案与业务中兼容的差异 本质从业务抽象的要求，转移到业务边界的划分 粗粒度的业务抽象。 更灵活的定制化支持。 模块化方案落地的问题 需要有类数据仓库应用，存在数据组装的需求。 产品抽象的能力，无法剥离干净。 架构设计复杂，模块之间有依赖关系。 基于模型的日志类数据落地。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:3","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#模块化方案落地的问题 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#价值认可的问题 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#价值认可的解决方案 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#告知客户业务模型细节数据 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#感知通用模块和定制化模块的差异 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#按需使用让客户选择说不 class=headerLink"},{"categories":null,"content":"价值认可的问题自产，是否达到业务目标，还能如何改善，非常典型的降本增效的场景。 自销，功能是否清晰好用，是否能支持客户的业务流程。说白了，客户的好的结果跟工具无关，差的结果而又紧密相关。“系统太不好用，数据根本不适配”， “数据错了我也不知道”，“这个提示太不明显，都不知道怎么操作”。 价值认可的解决方案培养客户建立正确的系统价值认知，2B的Saas系统，不是企业定制管理系统，是提升企业能力的工具平台。 告知客户业务模型细节数据。这是客户付费得到的效果。 让客户感知通用模块和定制化模块的差异，为差异化的部分额外付费。 按需使用，让客户选择说不。 提供可选配的增值项目，为增值类项目额外付费。 告知客户业务模型细节数据这里强调一下，业务模型细节，并不是最终产生价值，能产生业务价值是使用系统的基础和前提，如果达不到一个客户预期的业务价值，这个系统工具就该被淘汰。 这里提到的功能价值是用户每一个付费模型化工具的流程数据。展示某一个模块被使用次数，被调用次数，产生的风险次数。 比如一个订餐系统，每次订餐的完成时间，用户在订餐系统的停留时间，支付下单的时间，购物车使用次数，购物车结算的时间等等。这些被称为业务的过程数据，也是使用这个系统的人对系统的价值认可。 感知通用模块和定制化模块的差异定制化，是需要额外支付费用的，这一点，客户是理解的。 但常常存在的问题是，如何评估定制化的价值，客户支付多少成本则不好评判。如何解决这个问题呢？ 定制化的前提是具有通用的工具能力。首先要让让客户体验通用的工具，和他们的定制业务的差异，这时工具价值客户心里是有预期的。 通用的工具是有价格锚点。比如按月使用费用，或一次性使用费用。 按需使用，让客户选择说不能不能提供客户按需使用的能力，让客户取消不好用的系统费用，提高用户体验？ 某个需求客户觉得不好用，这个很常见。很多功能并不适配，或者设计不合理，或者引起了市场问题，需要暂停。能不能让客户停用，并且把这部分价值还给客户？能不能客户直接体会到费用的直接变化？ 这个事情是Saas产品的另一个层级，是否是Saas化付费，2B项目的一个大问题，也是细化的收费不清晰，这个话题就不深度展开了。 但我们还是要考虑： 业务功能是否有可量化的费用标准。基于一个整体付费功能的框架下，标记出每一个模块的价值。 业务功能是否独立存在。移除后，是否可以在部署成本，流量成本，使用成本等方面，帮助用户节省价值。 提供可选配的增值项目，为增值类项目额外付费 提供更有效的策略算法。 提供更有效的评估工具。 提供AI工具的人工替代。 类似上述的的功能点可以作为选配的增值项目，功能价值，客户会用脚投票的。 额外有一些建议： 通过数据或系统工具，发掘客户的不合理流程等，帮助客户流程上提效的这类动作，会很好的提高用户满意度，但并不适合额外收费。因为对方没有直接的受到“服务感”。 引入更好的工具，比如人工智能，类似AI语音的应用，但不要陷入高科技陷阱，很多项目中，客户的使用落差大，会极大影响项目认可度。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:4","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#提供可选配的增值项目为增值类项目额外付费 class=headerLink"},{"categories":null,"content":"自销的转变，是理念的转变过去的公司内部的平台化项目，侧重的还是对业务方价值的追求，与“业务”在同一战线上思考。在过程中，不可避免的忽略到一些“不太重要”的中间过程。特别有很多公司会有辅助的类似数据分析人员，来分担业务功能价值。 当系统对外输出，显著的转变就是价值评估标准变化。从系统部署，配置使用到操作过程体验，都是系统的考核标准，而结果相对重要性变得比较低。这并不是说结果不重要，恰恰相反，要让客户感知到系统深度的参与到了他们的业务中，提供了各种视角的过程数据，让客户对系统感知透明，可控可操作性，帮助他完成了工作。 这个客户的“体验感”才是真正价值。 跨过这一步，在具备“体验感”，才能提供更多的增值类的工具，才能做到跟客户的更好配合，创造出的更多的业务增量。 ","date":"2022-07-14","objectID":"/2b_saas_modularity_exploration/:0:5","series":null,"tags":null,"title":"2B的平台工具的自产转自销？","uri":"/2b_saas_modularity_exploration/#自销的转变是理念的转变 class=headerLink"},{"categories":null,"content":"Prometheus计算增量的场合，遇到了初始值计算偏差的问题，无法得到准确的增量","date":"2022-04-24","objectID":"/prometheus_increase_from_zero/","series":null,"tags":null,"title":"Prometheus中increase计算的初始值问题","uri":"/prometheus_increase_from_zero/"},{"categories":null,"content":"问题背景在一些业务中，Prometheus常被用来做数据监控和报警。 我们是一个2B的saas系统，使用Prometheus做B端用户的分配场景的数据统计。但在测试中，我们发现统计数据不准的问题。问题如下： 真实的业务中，在单位时间内，用户收到50单数据，但是Prometheus计算出的结果为48单。查询Grafana上的数据，可以看到用户收到的50单的增量日志图，但接口计算返回值48，这是什么问题呢，难道是官方接口有问题。 ","date":"2022-04-24","objectID":"/prometheus_increase_from_zero/:0:1","series":null,"tags":null,"title":"Prometheus中increase计算的初始值问题","uri":"/prometheus_increase_from_zero/#问题背景 class=headerLink"},{"categories":null,"content":"技术相关数据现在有4台业务应用服务器，我们采用的是间隔15秒节点数据采集一次。 在30分钟内会将60万数据分配给大概100多个用户，每秒分配400单。 每个人平均每秒分到4单。 现在要统计这个单位时间内每个人分到的数据量。 ","date":"2022-04-24","objectID":"/prometheus_increase_from_zero/:0:2","series":null,"tags":null,"title":"Prometheus中increase计算的初始值问题","uri":"/prometheus_increase_from_zero/#技术相关数据 class=headerLink"},{"categories":null,"content":"补充说明当然上述数据使用关系型数据库查询也是可行的，成本并不高，但是考虑到分配量告警等后续很多操作，选用的Prometheus。这部分就暂且不在深入讨论。 ","date":"2022-04-24","objectID":"/prometheus_increase_from_zero/:0:3","series":null,"tags":null,"title":"Prometheus中increase计算的初始值问题","uri":"/prometheus_increase_from_zero/#补充说明 class=headerLink"},{"categories":null,"content":"技术方案我们使用的 sum(increase) ","date":"2022-04-24","objectID":"/prometheus_increase_from_zero/:0:4","series":null,"tags":null,"title":"Prometheus中increase计算的初始值问题","uri":"/prometheus_increase_from_zero/#技术方案 class=headerLink"},{"categories":null,"content":"RabbitMQ和ApacheKafka的差异，什么时候选择哪一款？","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/"},{"categories":null,"content":"写在最前本文翻译/修改自博客文章 https://stiller.blog/2020/02/rabbitmq-vs-kafka-an-architects-dilemma-part-1/ https://stiller.blog/2020/02/rabbitmq-vs-kafka-an-architects-dilemma-part-2/ 当我面临着实践中的困境，两种工具都在日常使用。对MQ和Streaming存在困惑后，找到了一个能解决困惑的文章。记录在自己的blog中，后续会根据自己的知识，补足Kafka一些具体的场景和问题。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:1:0","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#写在最前 class=headerLink"},{"categories":null,"content":"困惑Kafka 和 RabbitMQ，很像，什么场景选择哪一个很困惑。这背后更多的一个事情是，Streaming 和 Message Queue的差异性是什么。 基于这个问题，讨论下两种模式的内部结构。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:2:0","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#困惑 class=headerLink"},{"categories":null,"content":"解惑","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:0","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#解惑 class=headerLink"},{"categories":null,"content":"异步消息模式这种传递消息的方式，分离生产者和消费者。处理异步消息，通常会选择两种模式–消息队列和发布/订阅 消息队列发布/订阅","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:1","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#异步消息模式 class=headerLink"},{"categories":null,"content":"异步消息模式这种传递消息的方式，分离生产者和消费者。处理异步消息，通常会选择两种模式–消息队列和发布/订阅 消息队列发布/订阅","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:1","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消息队列 class=headerLink"},{"categories":null,"content":"异步消息模式这种传递消息的方式，分离生产者和消费者。处理异步消息，通常会选择两种模式–消息队列和发布/订阅 消息队列发布/订阅","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:1","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#发布订阅 class=headerLink"},{"categories":null,"content":"RabbitMQRabbitMQ是消息代理（MessageBroker）的实现，也通常成为Service Bus。消息代理的流行产品还包括 ，ActiveMQ，Azure ServiceBus，Amazon Simple Queue Service（SQS） Queue模式 Apache KafkaKafka不是消息代理（MessageBroker）的实现，是一个分布式流平台（distributed streaming platform）。同样的流行产品包括，Azure Event Hubs， AWS Kinesis Data Streams Topic模式 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:2","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#rabbitmq class=headerLink"},{"categories":null,"content":"RabbitMQRabbitMQ是消息代理（MessageBroker）的实现，也通常成为Service Bus。消息代理的流行产品还包括 ，ActiveMQ，Azure ServiceBus，Amazon Simple Queue Service（SQS） Queue模式 Apache KafkaKafka不是消息代理（MessageBroker）的实现，是一个分布式流平台（distributed streaming platform）。同样的流行产品包括，Azure Event Hubs， AWS Kinesis Data Streams Topic模式 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:2","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#apache-kafka class=headerLink"},{"categories":null,"content":"显著差异（Message Ordering）RabbitMQ 是一个 消息代理，而 Apache Kafka 是一个 分布式流平台，这是个底层不同目标的设计产品。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:3","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#显著差异message-ordering class=headerLink"},{"categories":null,"content":"消息排序RabbitMQ：对消息顺序不提供任何顺序保障。当需要顺序性的场合，需要仅限于一个消费者，这牺牲并发的性能。当出现例如消费超时重试的场合，无法保证优先消费，RabbitMQ关于信息消费的方式如下： Kafka：提供了可靠的消息顺序保证。所有发送到同一个topic的消息，都会按照顺序处理。生产者可以在每条消息通道上设置分区键以创建数据流，让消费者顺序处理。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:4","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消息排序 class=headerLink"},{"categories":null,"content":"消息路由（Message Routing）RabbitMQ：可以根据订阅者定义的路由规则，将消息交付。允许消费者消费指定的消息类型。 消息队列的使用过程大概如下： （1）客户端连接到消息队列服务器，打开一个channel。 （2）客户端声明一个exchange，并设置相关属性。 （3）客户端声明一个queue，并设置相关属性。 （4）客户端使用routing key，在exchange和queue之间建立好绑定关系。 （5）客户端投递消息到exchange。 Kafka：不允许消费者在轮询消息之前过滤主题中的消息。需要接收分区中的所有消息。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:5","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消息路由message-routing class=headerLink"},{"categories":null,"content":"消息时间（Message Timing）RabbitMQ：提供了多种功能： 消息生存时间（TTL）：自动删除过期消息，并放入死信队列中。 延迟消息：通过一些消息中间件，提供了延时发送消息的功能。 Kafka：不支持此功能。Kafka作为一个流平台，的设计目标是实时到达写入分区，提供消费者立即使用。Kafka的本质是写入分区Log，可以通过Log日志记录删除的方式清理事务日志，但这并不是为了解决消息时间。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:6","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消息时间message-timing class=headerLink"},{"categories":null,"content":"消息保留（Message Retention）RabbitMQ：消息消费后，会立即删除，这是所有消息代理设计的一部分。 Kafka：Kafka设计保存所有Topic的日志。并不关心Topic的消费状态。消费者可以根据偏移量随时调整过去的消费信息。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:7","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消息保留message-retention class=headerLink"},{"categories":null,"content":"故障处理（Fault Handling）这里两种方案有非常明显的不同： RabbitMQ：当消费者处于处理消息故障的场合，其他消费者可以处理后面的消息。与消息的无序性有关系 Kafka：消费者出现重试的场合，是无法消费后面的消息。解决办法是手动调整消费偏移量。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:8","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#故障处理fault-handling class=headerLink"},{"categories":null,"content":"规模（Scale）通常来说，大家会认为Kafka提供了更好的性能，这基于Kafka使用顺序I/O，零拷贝等的设计机制。一般来说十万/秒的消息支撑能力是很容易的。 但RabbitMQ集群也是能足够支撑几万/秒的能力。 重要的是，一般规模的应用，是用不到如此高性能的规模。这两个模式都能很好的支持。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:9","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#规模scale class=headerLink"},{"categories":null,"content":"消费者复杂性（Consumer Complexity）RabbitMQ：智能代理和愚蠢消费者（a smart broker / dumb consumer model ），可以灵活支撑消费者的扩展。 Kafka：愚蠢代理和智能消费者（a dumb-broker / smart consumer model ），需要在消费者内部协调主题分区。 kafka在负载的增加减少的场合，需要做更多的努力。Kafka-SDK会帮我们做一部分额外的工作。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:10","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#消费者复杂性consumer-complexity class=headerLink"},{"categories":null,"content":"如何选择我们面临着不同的业务场景中选择消息模式，究竟要如何选择呢，基于上面的差异，我们能得到下面的这些结论。 使用RabbitMQ更合适的场景： 需要很灵活的路由规则 需要定时/延时控制消息 避免依赖消费者处理错误消息 更简单的消费者要求 使用Kafka更合适的场景： 消息严格排序 实时要求 消息保存的持久性，重播消息的功能 极高并发的要求。 除此之外，还要考虑研发人员对上述技术能力的掌握程度。例如KafkaSDK的学习成本。 很多场合，两种模式也能共存，这取决于维护人员成本。 例如基于事件驱动架构的系统中，使用RabbitMQ发送点对点的服务调用，解耦函数依赖。使用Kafka发送业务事件通知。比较显著的原因是，作为业务事件的存储和重放 ，是事件驱动架构设计的一个核心诉求。Kafka的事件保存机制更合理。另一方面，当我们需要解耦动作依赖，重试的场景下，RabbitMQ的表现更加突出。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:3:11","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#如何选择 class=headerLink"},{"categories":null,"content":"结论通过比较这两种模式，本质上的MQ和Streaming的异同，很多场景下，双方是可以互换的。但由于底层设计模型的不同，在一些细分场景下，两者也会有显著的优缺点。这需要架构师深入理解后，做更合适的选择。 ","date":"2022-03-19","objectID":"/rabbitmq_vs_kafka/:4:0","series":null,"tags":null,"title":"RabbitMQ 对比 Apache Kafka","uri":"/rabbitmq_vs_kafka/#结论 class=headerLink"},{"categories":null,"content":"AWS EC2 Trojan 部署","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/"},{"categories":null,"content":"什么是Trojan详细请自行Google或Baidu。 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:1:0","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#什么是trojan class=headerLink"},{"categories":null,"content":"部署前提 域名。必须使用域名，可以没有SSL证书。本文采用Namecheap注册的二级域名做demo。 可连接上网的VPS。各种云服务商均可，本文以AWS的EC2做Demo。 AWS提供一年免费的服务器，每个月750小时的访问。 Azure提供USD200额度的免费账户。 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:2:0","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#部署前提 class=headerLink"},{"categories":null,"content":"部署流程","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:0","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#部署流程 class=headerLink"},{"categories":null,"content":"1. 创建EC2省略截图 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:1","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#1-创建ec2 class=headerLink"},{"categories":null,"content":"2. 连接EC2省略截图 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:2","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#2-连接ec2 class=headerLink"},{"categories":null,"content":"3. 安装。 （以下参照 https://github.com/Jrohy/trojan 大神做好的部署环境，可直接跳转参照） [ec2-user@ip-172-31-30-131 ~]$ source \u003c(curl -sL https://git.io/trojan-install) 正在安装trojan管理程序.. Error: You must be root to run this script 提示需要使用Root用户 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:3","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#3-安装-以下参照-httpsgithubcomjrohytrojan-大神做好的部署环境可直接跳转参照 class=headerLink"},{"categories":null,"content":"4. 使用root [ec2-user@ip-172-31-30-131 ~]$ sudo passwd root Changing password for user root. New password: Retype new password: passwd: all authentication tokens updated successfully. ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:4","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#4-使用root class=headerLink"},{"categories":null,"content":"5. 切换root [ec2-user@ip-172-31-30-131 ~]$ su Password: [root@ip-172-31-30-131 ec2-user]# ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:5","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#5-切换root class=headerLink"},{"categories":null,"content":"6. 重新安装Trojan #安装/更新 source \u003c(curl -sL https://git.io/trojan-install) #卸载 source \u003c(curl -sL https://git.io/trojan-install) --remove ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:3:6","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#6-重新安装trojan class=headerLink"},{"categories":null,"content":"Trojan客户端","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:4:0","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#trojan客户端 class=headerLink"},{"categories":null,"content":"移动版推荐使用 Shadowrocket，真的是百搭，支持多种协议。IOS需要在，美国应用市场，现在3.5美金。 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:4:1","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#移动版 class=headerLink"},{"categories":null,"content":"电脑版可以使用TrojanX。 下载推荐除IOS外，可前往 https://dl.trojan-cdn.com/trojan/ 下载客户端。 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:4:2","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#电脑版 class=headerLink"},{"categories":null,"content":"电脑版可以使用TrojanX。 下载推荐除IOS外，可前往 https://dl.trojan-cdn.com/trojan/ 下载客户端。 ","date":"2022-02-06","objectID":"/deploy_trojan_in_aws_ec2/:4:2","series":null,"tags":null,"title":"部署Trojan","uri":"/deploy_trojan_in_aws_ec2/#下载推荐 class=headerLink"},{"categories":null,"content":"个人使用技术栈","date":"2022-02-04","objectID":"/technical-graph/","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/"},{"categories":null,"content":"这篇文章，是受到这个博主的（https://www.bmpi.dev/dev/tech-stack-of-side-project/ ）的启发，记录一下自己这些年使用的并留下来的技术盏。 一方面，可以对自己有更清楚的认识；另一方面，如果有人看这个私人博客，可以快速了解博主的技术水平，如若得不到价值，可减少不必要的时间浪费。 ","date":"2022-02-04","objectID":"/technical-graph/:0:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#"},{"categories":null,"content":"编程语言作为一个后端的程序开发设计人员，秉持着设计大于语言实现。但没有尝试更多的技术语言，无法在比较中有任何的发言权利，这点正在检讨中。 JAVA：过去的很多年，一直在使用这一个模型。遇到项目的第一反应，使用gradle或maven去构建一个springboot的项目。这有效，但是似乎是个坏习惯，屏蔽了新技术的应用。 GO：正在尝试使用GO，去替换业务中一个小型业务模块，促进对非语言依赖的RPC框架的使用。 Python：使用Python给我女儿讲解一些可视化的编程课程。学习了一部分的Python语法。正在学习使用Python替代Excel作为特定场景计算应用。现在看大火的技术语言，在数据分析领域有高效，学习成本低等天然优势。 ","date":"2022-02-04","objectID":"/technical-graph/:1:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#编程语言 class=headerLink"},{"categories":null,"content":"技术框架 Dubbo：用了很多年的Dubbo2.x的RPC框架，为数不多的认真的读过传输模型的核心代码。这个框架，使用的Netty的NIO，足够简单专注，成本低，速度快，适合小型团队的快速应用。但也存在很多被诟病的问题，启动扫描成本高，在庞大冗杂的业务系统面前，面对几千甚至更多的服务列表，单纯的服务治理对项目管理来说显得无能为力。好消息是2021年，3.0版本被发布出来，还尝试支持gRPC的通信，期待这个框架能够再次活跃起来。 SpringCloud：如果说Dubbo是个服务治理框架，实际上的SpringCloud的全家桶更多的是面对微服务概念产生的一个服务管理生态。包括负载均衡，流量治理，熔断等等，特别是支持第七层的Rest服务调用，考虑到近年飞速发展的容器技术，丛云原生到服务网格等等，与dubbo相比，这两者就是兼容和不兼容的本质区别。SpringCloud背后还有想Netflix，Alibaba等大厂支持，还是当下JAVA领域最成熟的解决框架。 Service Mesh：严格的说，这不是一个技术框架，而是要配合容器技术这种行业发展趋势，接触如gRPC这种跨语音的RPC解决方案。这个模型还在学习使用中，等掌握之后再更新。 ","date":"2022-02-04","objectID":"/technical-graph/:2:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#技术框架 class=headerLink"},{"categories":null,"content":"架构模型作为后端架构师，习惯性的做领域模型设计，拆分服务模型，支持服务级别快速拆分，支持服务级别快速扩容。过去几年的项目中，经历了底层环境变化，插件式的功能拼装，做了非常多的服务间的拆拆合合。深刻的体会到服务化“规范”的价值。 微服务：所有公司级别项目，都遵循这个服务模型，dubbo/springcloud的框架下的springboot的应用管理。 Serverless：最近尝试将个人项目Serverless应用化，成本评估是主要原因，也看好几年内的这个领域的快速发展。 ","date":"2022-02-04","objectID":"/technical-graph/:3:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#架构模型 class=headerLink"},{"categories":null,"content":"数据存储数据处理是我们所有产品/应用的最终目的。过去工作中的主要数据存储工具，是数据库层级的Mysql和对象层级的Ceph。个人存储会在网盘文件中。现在逐渐在使用一些新鲜的事务。 Mysql：作为应用产品系统架构师，OLTP领域，还是首选Mysql，绝大多数的工作也是在这里，没什么说的。优缺点，网上很透彻了。 Tidb：2020年引进到系统中。对比Mysql，它在亿级别单表上的操作上表现很好。在没使用Tidb前，为了避免做分库分表这个单向门操作，做了很多方案。包括影响业务的定期归档，冷热表分离，以及使用ElasticSearch做查询等。另一方面，Tidb还有一定的OLAP能力，具有小型的连表查询分析能力。对比Mysql来说，缺点是成本较高，一组高可用性最低模型需要八个节点。Mysql是三个。磁盘性能要求也比较高。他的分析能力也无法跟专门的分析性数据库对比。是一个主OLTP兼OLAP场景的不错的解决方案。 Redis：Redis集群，主要以缓存的方式出现，提升系统的查询能力，常见的使用是加载Tidb等生成的数据，降低数据库压力。还有一个重要的作用是分布式应用的锁，比起依赖ZK的锁更常用一些。 Memcache：在小型的独立项目中还是比较常用，降低数据库压力。在一些特定的高并发场景有不错的表现。但总得来说，我接触的Memcache场景已经不多了。 MangoDB：在之前配合算法同学做的机器人项目中，“被动”接触了MangoDB，在非结构化数据模型的实时查询领域，有很好的的表现，其他的优点体验的不多，其他项目并没有应用。 Hbase：公司项目中主要的数据仓库。主要作用是离线数据分析使用。ETL是个比较麻烦的事情，毕竟数据分析的同学并不擅长数据结构设定，合适的拆分关系型数据库模型，对架构师能力有很高的要求，同样的，从拆分的关系构建一张width-column数据模型的能力，也一样重要。 Amazon DynamoDB：近期正在个人项目中接触的数据库存储，配合Serverless模型的应用，尝试将OLTP部分，移植到一个Nosql的项目中，看看会有什么问题。 Amazon S3：同样是由于Serverless模型中，对象存储的存在。这部分还在学习状态，等待日后更新。 ","date":"2022-02-04","objectID":"/technical-graph/:4:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#数据存储 class=headerLink"},{"categories":null,"content":"基础服务 AWS：大量的托管类服务。行业顶级的Paas/Saas工具。很多我打算在Aliyun使用的功能，都会现在AWS上找对应工具进行体验。但是记得有些服务要及时删除，部分服务费用昂贵。 AliYun：国内最好的云服务商。一些工作的项目，正在逐渐迁移到阿里云的EKS的云原生环境上。 Namecheap：域名注册商。 ","date":"2022-02-04","objectID":"/technical-graph/:5:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#基础服务 class=headerLink"},{"categories":null,"content":"部署 Docker：容器化是现在，也是可以看到的时间里的未来。工作中的应用环境，全部在Docker容器上；个人项目中，受限一些部署迁移的工具，也仍然在使用虚拟机。 Kubernetes：工作中，使用私有云环境K8s集群，正在迁移阿里云EKS集群中。学习成本比较高。两个小建议：1. 经验不足使用托管EKS。2. 虚拟机 or 容器集群？ 容器集群；容器集群的成本在初期会略微贵一点点，但规模化后，节点利用率高，边际成本低。 ","date":"2022-02-04","objectID":"/technical-graph/:6:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#部署 class=headerLink"},{"categories":null,"content":"开发工具 Github：无需多说，源码管理。我的Blog的内容也在Github上托管。 InteliJ IDEA：最主要的JAVA项目开发调试工具，缺点就是太重了。 VSCode：主要在写文章，写团队博客中使用。最近也尝试在阅读代码中使用VSCode替代InteliJ，最重要的原因是轻量级，不会引起风扇噪音。插件丰富，能满足绝大多数的工作需要。准备再使用一段时间，看看能否将开发工作也迁移过来。 ","date":"2022-02-04","objectID":"/technical-graph/:7:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#开发工具 class=headerLink"},{"categories":null,"content":"设计 OmniGraffle：个人使用比较习惯的绘图工具，用来画架构，流程图。他有很多模板（stencil）下载，方便拖拽选用。 Axure：产品原型工具。日常项目中，有很多技术驱动的产品设计，需要画出来与产品研发同学沟通，这个工具搭建简易原型要更有效率。顺便多说一句，项目设计时，一图胜千言。 ","date":"2022-02-04","objectID":"/technical-graph/:8:0","series":null,"tags":null,"title":"个人使用技术栈","uri":"/technical-graph/#设计 class=headerLink"},{"categories":null,"content":"测试Lambda函数的线程数量和内存配置影响","date":"2022-02-03","objectID":"/lambda_processor/","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/"},{"categories":null,"content":"背景部署一个应用，我们需要确定一下成本和性能，Lambda函数也一样。按照AWS的说明，默认的Lambda是512M内存的配置，可以上线到10GB，但没有CPU核数的选项。我们是否能充分利用一个Lambda函数的全部性能呢。 ","date":"2022-02-03","objectID":"/lambda_processor/:1:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#背景 class=headerLink"},{"categories":null,"content":"本地我们部署下面一段代码，使用系统默认线程池来测试一下线程的支持情况。 logger.info(\"availableProcessors: \" + Runtime.getRuntime().availableProcessors()); IntStream.range(1, 10).parallel().forEach(id-\u003e{ logger.info(\"Thread: \" + Thread.currentThread()); logger.info(\"ForkJoinPool Size: \" + ForkJoinPool.commonPool().getPoolSize()); try { Thread.sleep(2000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); 我本地cpu是i5，2核线程增强型，所以应该有4个并发线程可以使用。结果也如预期； 12:11:08.888 [main] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - availableProcessors: 4 12:11:09.038 [main] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[main,5,main] 12:11:09.038 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 12:11:09.038 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:09.038 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-2,5,main] 12:11:09.038 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:09.038 [ForkJoinPool.commonPool-worker-3] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-3,5,main] 12:11:09.039 [ForkJoinPool.commonPool-worker-3] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:09.040 [main] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:11.039 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 12:11:11.039 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-2,5,main] 12:11:11.039 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:11.039 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:11.039 [ForkJoinPool.commonPool-worker-3] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-3,5,main] 12:11:11.039 [ForkJoinPool.commonPool-worker-3] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:11.045 [main] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[main,5,main] 12:11:11.045 [main] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 12:11:13.093 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - Thread: Thread[ForkJoinPool.commonPool-worker-2,5,main] 12:11:13.093 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.threadinlambda.ThreadInLocalApplication - ForkJoinPool Size: 3 ","date":"2022-02-03","objectID":"/lambda_processor/:2:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#本地 class=headerLink"},{"categories":null,"content":"Lambda 512M版本把同样的代码，发布到AWS上的Lambda函数上，使用默认配置，内存512M。结果如下： 2022-01-26T11:37:55.450+08:00 03:37:55.447 [main] INFO com.snack.learning.ThreadInLambda - availableProcessors: 2 2022-01-26T11:37:55.455+08:00 03:37:55.455 [main] INFO com.snack.learning.ThreadInLambda - Thread: Thread[main,5,main] 2022-01-26T11:37:55.455+08:00 03:37:55.455 [main] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:37:55.455+08:00 03:37:55.455 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 2022-01-26T11:37:55.455+08:00 03:37:55.455 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:37:57.455+08:00 03:37:57.455 [main] INFO com.snack.learning.ThreadInLambda - Thread: Thread[main,5,main] 2022-01-26T11:37:57.456+08:00 03:37:57.455 [main] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:37:57.456+08:00 03:37:57.455 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 2022-01-26T11:37:57.456+08:00 03:37:57.456 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:37:59.456+08:00 03:37:59.456 [main] INFO com.snack.learning.ThreadInLambda - Thread: Thread[main,5,main] 2022-01-26T11:37:59.456+08:00 03:37:59.456 [main] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:37:59.456+08:00 03:37:59.456 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 2022-01-26T11:37:59.456+08:00 03:37:59.456 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:38:01.456+08:00 03:38:01.456 [main] INFO com.snack.learning.ThreadInLambda - Thread: Thread[main,5,main] 2022-01-26T11:38:01.456+08:00 03:38:01.456 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - Thread: Thread[ForkJoinPool.commonPool-worker-1,5,main] 2022-01-26T11:38:01.456+08:00 03:38:01.456 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:38:01.456+08:00 03:38:01.456 [main] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 2022-01-26T11:38:03.457+08:00 03:38:03.457 [main] INFO com.snack.learning.ThreadInLambda - Thread: Thread[main,5,main] 2022-01-26T11:38:03.457+08:00 03:38:03.457 [main] INFO com.snack.learning.ThreadInLambda - ForkJoinPool Size: 1 可以看到，Lambda函数是单核线程增强型，共有2个进程。 ","date":"2022-02-03","objectID":"/lambda_processor/:3:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#lambda-512m版本 class=headerLink"},{"categories":null,"content":"Lambda 2048M版本我们尝试增加Lambda使用内存数，日志结果没有区别，还是2个线程数。 ","date":"2022-02-03","objectID":"/lambda_processor/:4:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#lambda-2048m版本 class=headerLink"},{"categories":null,"content":"结论从Lambda的参数设定，推测Lambda函数设计有两点： 1. 单线程。函数就是无状态的实例节点，并发调用的场合，交给上游Lambda函数并发调用。 2. 提升单线程的执行效率。通过内存的提升，提升一个函数的响应时间，AWS也增加了15分钟的超时限制。尽可能的限制函数的复杂性。 我们部署函数，也要遵循上述的方式，尽量把函数拆成单一的动作及结果返回，才能最大程度的利用函数自身的特性。 ","date":"2022-02-03","objectID":"/lambda_processor/:5:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#结论 class=headerLink"},{"categories":null,"content":"代码参照你可以通过 https://github.com/snack8310/thread-in-lambda 下载源代码 ","date":"2022-02-03","objectID":"/lambda_processor/:6:0","series":null,"tags":null,"title":"Lambda的线程数","uri":"/lambda_processor/#代码参照 class=headerLink"},{"categories":null,"content":"了解AWS的Lambda函数，体验AWS上无服务化应用和API网关的部署过程","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/"},{"categories":null,"content":"什么是Lambda函数Lambda是AWS面向开发人员推出的应用层级Serverless解决方案。使用通过符合Lambda规范的代码，在AWS的环境上快速部署线上使用。通过配置支持自动扩容，安全，权限，网关等，完全屏蔽底层服务器管理的功能。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:1:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#什么是lambda函数 class=headerLink"},{"categories":null,"content":"Lambda的优势根据AWS的Blog的宣传，我们看到Serverless的优势包括一下几个点 # 无服务器管理 # 连续缩放 # 毫秒级 # 丰富生态 # 增加创新 我们部署一个Lambda，体验一下这些功能点。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:2:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#lambda的优势 class=headerLink"},{"categories":null,"content":"AWS Lambda实践","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#aws-lambda实践 class=headerLink"},{"categories":null,"content":"基本使用Lambda的函数开发，支持多种语言版本，包括Node.js 12.X，14.X, .Net Core 3.1, Python3.6-3.9, Ruby2.7,Java 8,11等，我们开发一个Java版本的函数。 可以通过本地IDE编写，也可以通过AWS提供的线上控制台，工具包等多种开发环境。 我们通过Java版本来体验一下。 本文代码可以在 https://github.com/snack8310/my-first-lambda 下载。本案例是个使用gradle的Springboot的工程。 也可以参照官方推荐的JAVA DEMO https://github.com/awsdocs/aws-lambda-developer-guide/tree/main/sample-apps/blank-java ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:1","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#基本使用 class=headerLink"},{"categories":null,"content":"基本概念Function：核心代码。 Trigger：触发器。例如APIGateway，SNS等，用来调用函数的资源。 Event：调用函数的数据。 Layer：Lambda 层是可以包含其他代码或其他内容的 .zip 文件归档。层可以包含库、自定义运行时、数据或配置文件。 其他的，不影响使用，可以慢慢扩展。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:2","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#基本概念 class=headerLink"},{"categories":null,"content":"核心函数解读 public class MyFirstLambdaRequestHandler implements RequestHandler\u003cAPIGatewayProxyRequestEvent, Object\u003e { private static final Logger logger = LoggerFactory.getLogger(MyFirstLambdaRequestHandler.class); @Override public Object handleRequest(APIGatewayProxyRequestEvent input, Context context) { logger.info(\"MyFirstLambdaRequestHandler: \" + input.getBody()); return new APIGatewayProxyResponseEvent().withBody(\"Hello world, \" + input.getBody()).withStatusCode(200); } } 代码引入了APIGateway调用方式的函数代理，做了简单的函数名称打印，准备做一个API网关调用的展示。 这个代码就是函数的入口和全部业务实现。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:3","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#核心函数解读 class=headerLink"},{"categories":null,"content":"创建层Layer（层）是个可选项，一个函数最多添加5层。层的引入，是为了缩小核心代码上传的部署成本，促进代码共享和责任分离，把公共部分，主要的jar包，放到公共层中，减少核心业务代码的变更成本。 执行Readme中的层编译代码生成层 set -eo pipefail gradle -q packageLibs mv build/distributions/my-first-lambda-0.0.1-SNAPSHOT.zip build/distributions/my-first-lambda-layer-0.0.1.zip 按照下属步骤部署一个新层 添加层 创建层 创建完成 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:4","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#创建层 class=headerLink"},{"categories":null,"content":"部署函数执行Readme中的层编译代码生成层 set -eo pipefail gradle build 按照下属步骤部署一个函数 修改运行时设置的处理程序 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:5","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#部署函数 class=headerLink"},{"categories":null,"content":"运行测试可以在本画面进行基本的调用测试 选择测试，可以直接点击测试，也可以模拟一个ApiGateway的调用，内容如下 { \"body\": \"snack\", \"isBase64Encoded\": true } 执行测试 执行成功。点击（日志），可以看到这次的测试结果 到此为止，我们已经部署了一个线上的应用服务。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:3:6","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#运行测试 class=headerLink"},{"categories":null,"content":"部署一个API网关，提供面向HTTP的访问。 创建网关 创建资源 创建方法 部署网关 AWS已经帮我们生成了一个对外可访问的网关，本地执行CURL，已经可以访问到。 huisheng@MacBook-Pro ~ % curl -X GET https://qvo9fbweyf.execute-api.us-east-1.amazonaws.com/dev/lambda -d '{\"body\":\"snack\"}' {\"statusCode\":200,\"body\":\"Hello world, snack\"}% huisheng@MacBook-Pro ~ % 到现在为止，在没有任何关于服务器的设定配置的情况下，我们已经在互联网上部署了一个对外提供服务的应用。整个过程非常简单方便。小小的体验了一把无服务化。 后续我们会针对Lambda的函数特点做一些简单的测试，包括连续缩放和性能。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:4:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#部署一个api网关提供面向http的访问 class=headerLink"},{"categories":null,"content":"Lambda 和 EKS（K8s）的对比截止到本文发表，EKS已经是个云原生毕业，经得住大规模商业化的考验的成熟产品。可以适配多种云环境，支撑面向应用的屏蔽底层容器环境的差异性。但需要具备ec2/pod/container级别的处理能力，这与通常的业务实现的技术领域不同。 Lambda这类Serverless服务，现在还是在经历高速商业化发展的初期。现在有一些制约：有一定的代码侵入性，并且尚不支持一个标准协议提供跨平台迁移性。系统设计层面，对比传统的领域模型，也要有一定的理念转变。但优点也非常突：屏蔽了底层容器级别的技术处理复杂度，而且在经济上有很大的提升空间。 可以根据具体的项目场景和资源配置，灵活的选择这两种方案。 个人角度看，他们可能不是竞争对手的关系，而是一种发展关系。 无服务器对于K8s，就像K8s对于容器一样。 ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:5:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#lambda-和-eksk8s的对比 class=headerLink"},{"categories":null,"content":"参照文章https://docs.aws.amazon.com/zh_cn/lambda/index.html https://docs.aws.amazon.com/zh_cn/whitepapers/latest/security-overview-aws-lambda/benefits-of-lambda.html ","date":"2022-02-02","objectID":"/make_a_lambda_in_aws/:6:0","series":null,"tags":null,"title":"在AWS上部署一个Lambda函数","uri":"/make_a_lambda_in_aws/#参照文章 class=headerLink"},{"categories":null,"content":"什么是Serverless？","date":"2022-01-30","objectID":"/serverless/","series":null,"tags":null,"title":"Serverless","uri":"/serverless/"},{"categories":null,"content":"什么是ServerlessServerless，直译过来，无服务器的意思。 当我们提到Serverless的时候，究竟是什么意思？ 本质上讲，无服务器是一种设计方法，可以构建一整套应用程序，而无需直接管理服务器的一种方法。 那Serverless的好处是什么？ 可以理解为无需直接管理服务器的好处是什么。等于服务器上都需要关心什么？从底下往上说，服务器：服务器配置，容量，性能；操作系统（OS）：版本，补丁，负载存储；容器（Container），版本，升级，编排，流量治理等等，直到应用层级。可以说，这里提到的点，就是Serverless好处。 Serverless是个典型的针对开发人员的架构技术。使用无服务器，我们不需要做任何其他的事情。部署即可用，可以自动扩容与缩减，不适用不付费；支持从CDN加速，应用，缓存，到存储及数据仓库。Serverless屏蔽了基础建设的复杂度，提供一个高可用的使用环境。提供更简单，友好的配置逻辑。及其快速的调用响应和休眠守护等功能。帮助开发人员减少部署成本，提高可扩展性。 广义上提到Serverless，会包括从应用被调用开始的资源，网关，应用，存储等等，整个环节的无服务器依赖。 但一般我们提到的Serverless，会主要集中在应用层面。主要原因是在这个链路上，制约无服务化的点，会出现在应用开发和数据存储的层面上。数据存储方面，通过一些Nosql的方式，能够通过脚本的扩容和缩放等可以自动维护的服务器的扩展性。但应用的场景就非常的复杂，如何能够更简单的维护应用环境是个非常大的挑战，这也是Serverless的概念的目的和起源。最早使用Serverless这个词的使用大约是2012年由Ken Form所写的一篇名为《Why The Future of Software and Apps is Serverless》的文章，也可以看出Serverless，现在更主要的集中在应用层面的解决方案上。 ","date":"2022-01-30","objectID":"/serverless/:1:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#什么是serverless class=headerLink"},{"categories":null,"content":"容器化技术演进应用层面的解决方案，是依赖容器化服务的技术演进。Serverless也可以说是在基于容器化服务上的一组应用方案。 这里拿AWS Lambda举例子，只要按照Lambda的规范增加lib和调用入口，就可以部署一个开箱即用的应用。 它提供了不需要管理基础设置，面向软件开发人员，解决除了开发业务功能外的基础设施相关的问题。包括服务器，虚拟机，容器，服务治理，权限等等。上述的所有功能，都提供了较为成熟完整的产品方案，Serverless对使用者，屏蔽了这些功能的配置复杂度. ","date":"2022-01-30","objectID":"/serverless/:2:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#容器化技术演进 class=headerLink"},{"categories":null,"content":"什么是Faas（Functions as a Service）整个Serverless的核心，就是函数化。 函数化的标准就是输入，输出。通过实现标准化的输入输出，解决与基础组件的调用问题。享受基础组件管理编排的有点。 通常Faas会跟微服务（MicroService）对比。本质上说，这两个并不冲突，一般来说，都会按照一个领域模型来划分边界。但函数化的单一输入输出来说，通常Faas会比微服务的领域模型更加碎片化，如果一个领域模型是某一个资源的CRUD，那么Faas很可能会把CRUD拆分成四个独立的函数，提供给外部调用方使用。 云服务商大多提供了自己的Serverless的产品：比如AWS的Lambda，Azure的Functions。国内厂商中，也有很多推出了自己的Serverless产品，比如阿里云，华为云。 ","date":"2022-01-30","objectID":"/serverless/:3:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#什么是faasfunctions-as-a-service class=headerLink"},{"categories":null,"content":"为什么用Serverless新技术的应用，一定是为了让业务速度更快，包括部署速度，成本更低。serverless的竞争对手，就是容器化的应用，我们用AWS的产品对比，lambda函数比EKS。 ","date":"2022-01-30","objectID":"/serverless/:4:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#为什么用serverless class=headerLink"},{"categories":null,"content":"部署更快上面说了，参照标准接口定义，从实现到部署可用，仅仅需要几行代码。远比EKS，需要部署容器节点，网关等等很多配置。 ","date":"2022-01-30","objectID":"/serverless/:4:1","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#部署更快 class=headerLink"},{"categories":null,"content":"成本更低从规模角度看，EKS，是一个独立隔离的容器组，提前预留了规模。Lambda可以想象为AWS统一管理的大池子，在性能未充分利用的场景，一定会低于预留规模的容器组。从第一性原则看，一定会比EKS这种预留规模的容器组，成本更低。 从人员角度看，EKS需要配置人员要更多的了解服务底层的概念，才能做合适的配置，很多时候，还是需要专业的infra人员进行管理。Lambda从设计开始，就是面向应用开发人员，这部分成本一定会有差距。 ","date":"2022-01-30","objectID":"/serverless/:4:2","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#成本更低 class=headerLink"},{"categories":null,"content":"扩展效率从现在主流的产品的现状来看，Lambda函数明显在扩展效率上，远超EKS的效率。这可能跟函数碎片化的启动和完整服务化启动，不同体量的启动的差距有关，从设计模式来说，函数式的serverless是要快很多的。当然，这部分两种产品都在快速发展，未来可能无限趋同。 ","date":"2022-01-30","objectID":"/serverless/:4:3","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#扩展效率 class=headerLink"},{"categories":null,"content":"缺点当然，serverless不是没有缺点。 第一，严重依赖某个服务商，无法做到云原生，现在这是非常重要的原因。 第二，serverless是对应用做了侵入，并且需要开发或架构师的思维做转变，能突破领域边界的碎片化应用。 第三，大规模的商业化应用，还未普及。 ","date":"2022-01-30","objectID":"/serverless/:4:4","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#缺点 class=headerLink"},{"categories":null,"content":"怎么用Serverless参照AWS的官方模型，基本上，Serverless函数都是应用在整个无服务的场景下；与传统微服务化相互融合的方案，通常采用的都是单向调用的方式。 ","date":"2022-01-30","objectID":"/serverless/:5:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#怎么用serverless class=headerLink"},{"categories":null,"content":"基本模式","date":"2022-01-30","objectID":"/serverless/:5:1","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#基本模式 class=headerLink"},{"categories":null,"content":"Lambda传递","date":"2022-01-30","objectID":"/serverless/:5:2","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#lambda传递 class=headerLink"},{"categories":null,"content":"与MicroService的调用具体使用的方案，我们在其他的文章中，会陆续分享给大家。 ","date":"2022-01-30","objectID":"/serverless/:5:3","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#与microservice的调用 class=headerLink"},{"categories":null,"content":"总结作为一个架构师来看，serverless一定是个领人激动的领域。这里有显著的成本下降，性能提升的空间，还可以把服务器的计算能力，发挥到更大。serverless也是个相对比较新鲜的领域，也是最近3，4年内发展起来的，需要我们更多的学习和研究。 ","date":"2022-01-30","objectID":"/serverless/:6:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#总结 class=headerLink"},{"categories":null,"content":"参照https://aws.amazon.com/cn/blogs/china/iaas-faas-serverless/ https://acloudguru.com/blog/engineering/what-is-serverless ","date":"2022-01-30","objectID":"/serverless/:7:0","series":null,"tags":null,"title":"Serverless","uri":"/serverless/#参照 class=headerLink"},{"categories":null,"content":"测试Lambda函数的线程数量和内存配置影响","date":"2022-01-26","objectID":"/lambda_concurrency/","series":null,"tags":null,"title":"Lambda并发测试","uri":"/lambda_concurrency/"},{"categories":null,"content":"并发的场景怎么体验Lambda的优点。 我做了两个简单的函数，一个只打印日志，一个增加了2s的Sleep @Override public Object handleRequest(APIGatewayProxyRequestEvent input, Context context) { logger.info(\"ApiGatewayRequestHandler: \" + input.getBody()); return new APIGatewayProxyResponseEvent().withBody(\"Hi \" + input.getBody()).withStatusCode(200); } @Override public Object handleRequest(APIGatewayProxyRequestEvent input, Context context) { logger.info(\"ApiGatewayParallelRequestHandler: \" + input.getBody()); try { Thread.sleep(2000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } logger.info(\"ApiGatewayParallelRequestHandler: after\"); return new APIGatewayProxyResponseEvent().withBody(\"Hi \" + input.getBody()).withStatusCode(200); } ","date":"2022-01-26","objectID":"/lambda_concurrency/:1:0","series":null,"tags":null,"title":"Lambda并发测试","uri":"/lambda_concurrency/#并发的场景 class=headerLink"},{"categories":null,"content":"本地调用启动10个线程，分别调用两个函数20次，我们观察下，两个函数会有什么变化。 ","date":"2022-01-26","objectID":"/lambda_concurrency/:2:0","series":null,"tags":null,"title":"Lambda并发测试","uri":"/lambda_concurrency/#本地调用 class=headerLink"},{"categories":null,"content":"结果 14:53:18.770 [ForkJoinPool.commonPool-worker-9] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.770 [main] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.770 [ForkJoinPool.commonPool-worker-11] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.776 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.897 [ForkJoinPool.commonPool-worker-13] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.909 [ForkJoinPool.commonPool-worker-10] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.916 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.928 [ForkJoinPool.commonPool-worker-15] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:18.978 [ForkJoinPool.commonPool-worker-6] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.015 [ForkJoinPool.commonPool-worker-9] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.020 [ForkJoinPool.commonPool-worker-2] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.023 [main] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.025 [ForkJoinPool.commonPool-worker-11] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.121 [ForkJoinPool.commonPool-worker-8] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.136 [ForkJoinPool.commonPool-worker-13] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.143 [ForkJoinPool.commonPool-worker-10] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.167 [ForkJoinPool.commonPool-worker-1] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.173 [ForkJoinPool.commonPool-worker-15] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 14:53:19.224 [ForkJoinPool.commonPool-worker-4] INFO com.snack.learning.lambda.snacklambda.SnackLambdaApplication - {\"statusCode\":200,\"body\":\"Hi null\"} 总时间，大概0.5秒，在AWS监控台上，看使用了8个并发实例 ","date":"2022-01-26","objectID":"/lambda_concurrency/:3:0","series":null,"tags":null,"title":"Lambda并发测试","uri":"/lambda_concurrency/#结果 class=headerLink"},{"categories":null,"content":"代码参照你可以通过 https://github.com/snack8310/snacklambda 下载源代码 ","date":"2022-01-26","objectID":"/lambda_concurrency/:4:0","series":null,"tags":null,"title":"Lambda并发测试","uri":"/lambda_concurrency/#代码参照 class=headerLink"},{"categories":null,"content":"架构设计中的扩展性在项目开发中，大家一定遇到过系统卡顿的场景，当我们想要解决系统瓶颈时，究竟该如何选择？ 欢迎观看系统架构设计系列内容，今天我们聊一下系统架构设计中的扩展性。 今天我们讲一个梦想书城的线上书店的故事。梦想书城有两个主要功能：查询、下单。 梦想书城初级版\" 梦想书城初级版 书城刚开业。里面只有1款书，库存10本。很快就吸引到50个用户访问，在10天的时间里卖完了全部10本书。书城收到钱，支付了服务器和网络的费用，可以继续扩大规模。现在有10款书，每款库存100本，共计1000本书。也很快，用户注册数量超过了2000。现在每天都有1000个用户访问，购买约100本书，按照有效销售的时间10小时计算，系统至少要求满足100个用户/时的访问，10本书/时的销售的吞吐量。吞吐量是用来衡量系统能力的重要指标。 如果服务器故障、断电等问题，每小时的故障就意味着10本书的损失。行业里流行的方案是使用云服务器，类似阿里云，亚马逊云等，这些云服务器可以帮助规避这些问题，专注在业务中。 梦想书城的工程师在阿里云上买了一台配置是2核4GB内存的服务器，把梦想书城运转了起来。1000本书又很快的卖光了，真是令人开心。 梦想书城高级版\" 梦想书城高级版 继续扩大规模，现在系统里有100款，每款500本，累计库存50000本。注册的用户数量也超过了10000人。原本预计，日销量能够到达1000本。但实际上只卖不到500本。 很快大量的用户反馈出现了：“系统查询太慢了，想要的书根本找不到”，“我选到了书，但是下单的时候需要等待”。 图片 系统崩溃了。 梦想书城的工程师想要尽快解决这个问题。考虑到书城的成长，为了支撑到日销2000本的能力，选择买一台更好的8核16GB内存的服务器，这种方案是否可行？工程师们做了深度的讨论。 最显而易见的优点：不需要改变任何代码逻辑。只需要升级硬件即可。 但这个方案会有潜在的问题。## 方案潜在的问题 服务器故障。如果只有一台服务器，故障了用户就无法访问。我们仍然担心这一台服务器出现故障。就算阿里云可以快速速诊断并且在3分钟内修复给用户使用，这其实仍然是一个很大的事故，造成了3/365(天)/24(时)/60(分)故障率，系统可用性降到99.9994%。 硬件限制。这是个致命的问题。预计在3个月后，梦想书店的用户和销量都能扩大10倍，未来也许更多，就像京东，当当的书城，每天可能是10万的订单。可是在阿里云的服务器里，找不到一个80核160GB的服务器，更不要说持续增长的未来。过去有一个词叫摩尔定律，每一年半，硬件性能提升一倍。虽然现在摩尔定律已经不那么准确，但显然是跟不上业务规模的成长。 有没有其他的方案呢。 梦想书城也可以选择买4台服务器，期待4倍的服务能力去解决这个问题。而且看上去能够规避升级硬件的问题。 方案最大的优点：突破硬件的限制，可以支撑40倍，400倍或更大的需求。 这个方案会有什么问题？ 系统故障。如果一台服务器发生了故障，这时候有1/4的人只能看到画面上尴尬的写着“404”，无论怎么刷新，都看不到书店任何内容。我们不能接受这种状况，实际上当时另外3台服务器都正常运行，必须要让用户访问到正常运转的服务器上，屏蔽错误的服务器。能完成这样功能的组件，就是负载均衡（load balance），它们也是一个机器，被设置在服务器前，当后端服务器故障，可以把用户访问指向可用的服务器上。当然这里有很多策略，这里暂不展开。 图片 数据不一致。现在有个用户把一款书最后一本买走了。他看到的库存从1变成了0。这是另一个用户登录在另一台服务器上，看到的库存还有1本。他是否能买到书？显然是不能的，工程师们要避免这种情况。这种数据不一致的情况，称为数据一致性（data consistency）问题。一种办法是，当有一个服务器卖书的时候，通知其他服务器不要卖书，但这是不切实际的。梦想书城的工程师们被迫优化新的代码，增加了非常多校准数据和同步数据的功能。 图片 性能下降。增加校验数据同步数据功能后，原本一个下单的动作，只要大概100ms，现在时间增加了一倍，200ms才能完成。这是因为原本系统内部的逻辑，变成服务器之间信息传递，增加了服务通信成本（network communication）。这些服务器之间的通讯，通常的方案是远程过程调用（RPC），会产生大量的网络IO访问。网络信息传递的速度，遥远大于系统内部的调用速度。 系统复杂度呈现指数级的膨胀。从服务器间的交互，前端和服务器，到服务器和数据库等等的交互，还需要增加很多工具组件，就像监控日志，系统检测，链路追踪，限流限速等等的需求。 图片 这些方案，实际上是系统设计领域里的重要概念：扩展性。如何选择和应对业务扩展需求，是互联网领域最重要的设计考量，甚至没有之一。 图片 更多的服务器的方案，提供更多请求响应的能力，称之为”水平扩展“（scale out）。买更好的服务器，提供更快，更好的单次响应性能，称之为”垂直扩展“（scale up）。 扩展性的本质，是基于某一垂直能力上的水平提升。很多场景，仍然可以通过垂直扩展解决问题，但这是有上限的，水平提升是几乎无上限的。 当面临需要扩展的需求时，具体选择哪种方案更合适呢？这里没有标准答案，都要结合实际情况考虑。 一般考虑方案，根据业务类型，做倾向性的选择。 对于梦想书城的查询功能的性能瓶颈，优先考虑垂直扩展。想象一下，好比在书城里扩建一个更大的展厅，摆放更多的书展示给用户。这种查询类动作，称为读操作，显著特征是很多人会共用一个查询结果，重复率较高。这种业务类型下，垂直扩展会更多一些。常见的解决方案是利用一些CDN，缓存，使用更多静态文件或者内存组策略。 对于梦想书城里下单等待的功能，优先考虑水平扩展。想象一下超市收银台的场景，把20个收银台增加到40个，就可以让同时结账的人数增加一倍。这种用户改变数据为目的的动作，称为写操作，显著特征是互相之间干扰较少，独立完成数据库的更新。写操作比较多的业务类型下，水平扩展会更多一些。常见的解决方案是增加线程，服务器，批量合并等等。 图片 另外，在一个项目的不同阶段来说，也会有些选择的倾向性。 通常来说，在项目初期出现性能瓶颈，会优先考虑垂直提升。这个阶段如何响应业务需求，推进业务发展，远比考虑负载均衡，考虑异地灾备等等重要的多。通过垂直提升，减少不必要的设计复杂度，让大家的焦点停留在业务上，避免精力分散。 在项目成长后，出现的性能问题，优先水平扩展为主。很多项目会经历业务的爆发式成长，必须要通过水平扩展来应对增长的规模。这个阶段也会衍生出很多类似服务治理，监控，限流，灾备等多种提高系统健壮性，可靠性为目标的功能。必要的场景下考虑更换底层技术方案，以解决性能瓶颈。 图片 最终，梦想书城的工程师们选择提升了2倍的机器性能，增加缓存集群，应对用户查询诉求；增加2台服务器，防止单点故障，并对应对可预期的下单量增长。 梦想书城这个案例给了我们一些启示。无论是什么场景，到哪个阶段，考虑扩展性的时候，权衡总是需要的。就像是分布式领域里著名的CAP定理，面对的性能和数据一致问题，项目过程中也总会面对在有限的时间内，适配未来更灵活还是现在更快等等问题。权衡能力的细微之处，也是一个架构设计好坏的差异，也是系统设计的目的。 这期系统扩展性的设计就说到这里，如果有什么疑问和建议，请随时留言给我，欢迎大家一起讨论。 ","date":"2021-12-27","objectID":"/scale_in_architecture/:1:0","series":null,"tags":null,"title":"系统设计中的扩展性","uri":"/scale_in_architecture/#架构设计中的扩展性 class=headerLink"},{"categories":null,"content":"大家好，今天我们聊一下什么是API，以及如何设计一个好的API。 ","date":"2021-12-27","objectID":"/what_is_a_good_api/:0:0","series":null,"tags":null,"title":"定义一个好的API","uri":"/what_is_a_good_api/#"},{"categories":null,"content":"什么是API？举个现实场景的例子，我们去餐厅吃饭，通过菜单了解到餐厅提供的美食清单，指定选择菜单上的菜品，得到我们想要的餐食。虽然我们并不了解餐食是如何做出来的，仍然可以通过这一方式获得想要的结果。这个过程，换成程序语言，就是一个调用API，获得结果的过程。 在一个编程的角度来说，API，Application Programming Interface，是预先定义好的一个应用程序接口。可以根据约定，提供外部系统或人员需要的应用程序内部的数据，而又不需要了解程序内部的实现过程或细节。 举个例子，梦想书城的项目开发中有一个动作，根据作者姓名得到作者信息。那么这个动作应该提供一个API，getAuthors，提供返回的作者们的名称，包括可能找不到作者的场景，提供一个查找不到的响应标识。 常见的API有很多，Web标准协议Restful API，Windows的动态链接库，Linux的POSIX等。一个API通常由方法名，参数和返回值组成，这和编程开发中的函数很像，明显的区别是是否屏蔽内部实现。 ​ ","date":"2021-12-27","objectID":"/what_is_a_good_api/:0:1","series":null,"tags":null,"title":"定义一个好的API","uri":"/what_is_a_good_api/#什么是api class=headerLink"},{"categories":null,"content":"什么是好的API？首先我们要明确，API是为了让外部系统调用的。那么最重要的一点，就是可以清楚的告诉外部系统，能得到什么，不能得到什么。判断一个API描述是否清楚，可以采用采用一个小技巧，遮挡住参数和返回值，能否根据方法名称猜到返回值和参数内容。 方法名称中要明确返回值的边界。根据刚才的梦想书城的例子getAuthors，这个API的返回结果应该有且只有一种，作者信息，仅限于作者这个模型特征的信息数据。API的数据提供方也限制在作者这个模型领域内。有一种情况，实际开发中经常会出现，调用方想要在返回结果中增加作者所在的作家协会，假如API中增加了类似的信息，那这个就不是一个合适的API定义。合适的办法是开发另外的API接口，并明确的指出返回值范围包括所属作家协会，例如getAuthorsWithOrgs。我们需要明确地返回值边界，确保getAuthors的所有使用方没有歧义。 方法参数要跟方法主体匹配。还是getAuthors的例子，根据这个名称，我们判断这个方法可以设置的参数大概是，作者姓名，作者年龄，性别等等，例如getAuthors（name），很多场合也可以用author.get（name）的方法，这两个含义相同，参数要限制在作者这个模型主体之内。如果有个场景是根据书名返回作者名称，那么强烈建议修改方法名称为getAuthorsByBookname，这种情况下，外部系统和开发者都很容易判定参数应该只有Bookname一种。 避免增加附加参数。很多“祖传”代码中常见的问题，例如getAuthors方法中，增加一个调用方的参数，并且通常能看到实现中有一段hardcode，写着如果是某个调用方，有些逻辑是特别的。这种特别的附加参数，对于方法描述是毫无意义的，但是对于外部系统调用方来说有很困惑。另一种，根据不同的附加参数，会执行不同的逻辑。假设现在有个方法setAuthor（author，org），要添加一个作者，如果作者有作家协会，同时更新所属协会。这种情况下，还是强烈建议修改名称，在方法描述中，体现出这个附加参数的含义。 ","date":"2021-12-27","objectID":"/what_is_a_good_api/:0:2","series":null,"tags":null,"title":"定义一个好的API","uri":"/what_is_a_good_api/#什么是好的api class=headerLink"},{"categories":null,"content":"清晰的定义一个API，对系统内部也会有很多好处。 降低IO开销。很多时候，一个API调用会对多个微服务模块进行调用，数据组装。这些IO调用的成本非常的昂贵。明确的API定义，能让外部系统调用方选择最准确的方法，避免无效的时间浪费。特别是现在互联网行业下，动辄数十万次的调用，累计起来的IO消耗非常大。 降低API重构风险。只做一件事，明确的API边界，意味着最小力度的访问关联的微服务，降低由于其他业务变化，引起的API实现逻辑变更。系统开发中，“蝴蝶效应”是非常明显的，经常会发生A系统的功能变化，莫名引起E系统的故障，一条链路上的B，C，D系统都需要跟着排查的事情。清晰的API边界能有效减少其他业务的耦合度，降低重构风险。 减少未来功能扩大化的风险。你永远不知道未来会发生什么，防止未来的同事，甚至自己，在这个方法中添加超出方法边界的功能，是让外部系统调用清晰以外最重要的一个价值。尽可能的做到参数准确定义，对潜在的风险给出明确的拒绝的含义。例如，getAuthorsByBookname，getAuthorsByBookId，要比GetAuthorsByBook，要好。getMaleAuthorsWithOrgs也要比getAuthorsWithOrgs（male）好很多，可以想象的未来getAuthorsWithOrgs的参数会增加到male，age，甚至create time这种非业务含义逻辑。 ","date":"2021-12-27","objectID":"/what_is_a_good_api/:0:3","series":null,"tags":null,"title":"定义一个好的API","uri":"/what_is_a_good_api/#清晰的定义一个api对系统内部也会有很多好处 class=headerLink"},{"categories":null,"content":"讲了最重要的方法定义，还有一些帮助我们建立好的API设计的实践经验。 明确的参数校验错误信息，减少不必要的参数校验。有些校验是必须的，例如非空判定，例如更新数据时的类型判断，我们要提供明确的错误信息，告知哪个字段为空，不是让外部系统猜测。但有些并不必要，可以减少API复杂度。例如查询参数过长，如果不会引起数据库异常，这个就是外部系统调用方的问题，结果只是查找不到，他们会自己发现问题。同样的，一个字符串的数值，也不需要判定是否传入一个整数，抛出奇怪的类型转换错误。尽量避免返回一个通用错误，例如，未知错误。 减少同时更新并查询的定义。这点在RestfulAPI上经常看到，例如想要查询作者信息，通过Get语义获得Authors，要比Post语义中返回Authors要好很多，并不仅仅是传递参数位置和大小的原因，使用Post语义容易产生更新数据的歧义。很多方法API定义中，setAuthors 或者 saveAuthors，会经常性同时返回一个结果，这样会有一定的隐患。例如我们想要增加缓存，缓存最佳实践中，建议更新的场景删除缓存，获取的场景设置缓存，这种同时返回结果，在并发的场景下，会产生脏数据，也会给使用方带来困惑。 明确单条和多条的查询结果使用不同的定义，多条返回结果中使用分页。例如getAuthorById，getAuthors。对于外部系统使用方，也容易判定如何使用，降低系统错误。强烈建议除非明确的返回数量含义，或者基于共识以外，要使用分页返回数据，并且给出的当前是第几页或者第几个游标。比如我们限定用户的收货地址，不超过5个，那么返回地址的API中，可以不用分页。但如果我们返回当前热销的书籍，尽量使用带分页的返回结果。也许后面的场景中，会出现最热销的100本的要求。 API调用量很大的场合，要分片，并且有结束标识。很多时候，会需要返回大量的数据，例如调用查询最近6个月的交易情况，也许这个动作会有上百kb的数据响应包。我们需要依次把分片的数据包发送给外部接收方，并且告知最后一个数据包，进行合并。当然同样的操作，也可以在分页定义数据中完成，但这增加了网络IO的调用次数，并增加了业务的复杂度。 增加缓存或增加限流限速措施。这两个放在一起的原因，是他们都是为了解决系统的可用性。一个例子是系统的评论系统，大部分场景，你并不关心过去几秒钟发生的评论信息，或者用户更新了头像，其他人默认看到的是昨天的头像，并不会造成什么问题。另外一些场景，外部系统的调用方，突然地大规模的调用API，可能会引起系统故障，那么就要增加限流措施等降级措施。比如梦想书城的供应商系统突然上传全部的库存书籍，这可能是不合理的，需要做一定的限制。 提供版本号。这一般发生在服务方，在外部系统调用方不可控的场景下。例如移动终端APP使用的后端服务，或者供应商使用的数据传输接口。这种一经发布，不可修改的业务场景，使用版本管理API定义是非常有效的API设计。 一个好的API定义，就是一种对功能范围的明确约定。对外部系统来说，约定的范围能避免业务分期；对内部服务来说，明确地范围能有效的降低未来的功能变更的风险。 如果你对上述的内容有任何的想法和建议，欢迎留言给我。非常感谢。 ","date":"2021-12-27","objectID":"/what_is_a_good_api/:0:4","series":null,"tags":null,"title":"定义一个好的API","uri":"/what_is_a_good_api/#讲了最重要的方法定义还有一些帮助我们建立好的api设计的实践经验 class=headerLink"},{"categories":null,"content":" Theme Documentation - Basics Discover what the Hugo - DoIt theme is all about and the core-concepts behind it. 阅读全文 Theme Documentation - Content Find out how to create and organize your content quickly and intuitively in DoIt theme. 阅读全文 Theme Documentation - Extended Shortcodes DoIt theme provides multiple shortcodes on top of built-in ones in Hugo. 阅读全文 ","date":"2021-11-01","objectID":"/showcase/:0:0","series":null,"tags":null,"title":"Showcase","uri":"/showcase/#"},{"categories":null,"content":" You are not connected to the Internet, only cached pages will be available. ","date":"0001-01-01","objectID":"/offline/:0:0","series":null,"tags":null,"title":"Offline","uri":"/offline/#"}]